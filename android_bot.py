import os
import sys
import json
import time
import asyncio
import ssl
import logging
import tempfile
import re
import html
import calendar
import shutil
import random
import atexit
import gc
from datetime import datetime, timedelta, timezone
from zoneinfo import ZoneInfo
from logging.handlers import RotatingFileHandler

# –°—Ç–æ—Ä–æ–Ω–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
from dotenv import load_dotenv
import aiohttp
import feedparser
from bs4 import BeautifulSoup
from telegram import Bot
from telegram.error import RetryAfter, TimedOut, NetworkError
from telegram.request import HTTPXRequest as Request
import aiosqlite

# ---- –ù–ê–°–¢–†–û–ô–ö–ò –ü–£–¢–ï–ô ----
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

def fix_path(name: str) -> str:
    return os.path.join(BASE_DIR, name)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv(fix_path(".env"))

# ---- –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ----
LOG_FILE = fix_path("bot.log")
# –§–æ—Ä–º–∞—Ç: –í—Ä–µ–º—è | –£—Ä–æ–≤–µ–Ω—å | –°–æ–æ–±—â–µ–Ω–∏–µ (–∫–æ—Ä–æ—Ç–∫–æ –¥–ª—è —ç–∫—Ä–∞–Ω–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞)
formatter = logging.Formatter("%(asctime)s | %(levelname)s | %(message)s", datefmt="%H:%M:%S")

# –†–æ—Ç–∞—Ü–∏—è: –º–∞–∫—Å 2 –ú–ë, —Ö—Ä–∞–Ω–∏—Ç—å 2 —Ñ–∞–π–ª–∞ (—ç–∫–æ–Ω–æ–º–∏–º –º–µ—Å—Ç–æ –Ω–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–µ)
file_handler = RotatingFileHandler(LOG_FILE, maxBytes=2*1024*1024, backupCount=2, encoding="utf-8")
file_handler.setFormatter(formatter)
file_handler.setLevel(logging.INFO)

console_handler = logging.StreamHandler(sys.stdout)
console_handler.setFormatter(formatter)

root_logger = logging.getLogger()
root_logger.setLevel(logging.INFO)
root_logger.addHandler(console_handler)
root_logger.addHandler(file_handler)

# –°–Ω–∏–∂–∞–µ–º —à—É–º –æ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("apscheduler").setLevel(logging.WARNING)

# ---- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ----
# –£–º–µ–Ω—å—à–∞–µ–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –±–∞—Ç–∞—Ä–µ–∏
CONCURRENCY = int(os.getenv("CONCURRENCY", "5"))
_network_semaphore = asyncio.Semaphore(CONCURRENCY)

BLOCKED_WORDS = [w.strip().lower() for w in os.getenv("BLOCKED_WORDS", "").split(",") if w.strip()]

DB_PATH = fix_path("bot_history.db")
META_FILE = fix_path("bot_meta.json")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ RSS
RSS_FILE = fix_path("rss.txt")
RSS_URLS = [u.strip() for u in os.environ.get("RSS_URLS", "").split(",") if u.strip()]
if os.path.exists(RSS_FILE):
    try:
        with open(RSS_FILE, 'r', encoding='utf-8') as f:
            file_urls = [l.strip() for l in f if l.strip() and not l.strip().startswith('#')]
            RSS_URLS.extend(file_urls)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è rss.txt: {e}")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Telegram
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
try:
    CHAT_ID = int(os.environ.get("CHAT_ID", "0"))
except:
    CHAT_ID = None

if not TELEGRAM_TOKEN or not CHAT_ID:
    logging.critical("‚ùå TELEGRAM_TOKEN –∏–ª–∏ CHAT_ID –Ω–µ –∑–∞–¥–∞–Ω—ã –≤ .env!")
    sys.exit(1)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ AI
GEMINI_KEYS = [k.strip() for k in os.getenv("GEMINI_KEYS", "").split(",") if k.strip()]
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
OLLAMA_MODEL = os.environ.get("OLLAMA_MODEL", "gemma2:2b") # –õ–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–∞

# –ü—Ä–æ—á–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
NEWS_LIMIT = int(os.environ.get("NEWS_LIMIT", 5))
INTERVAL = int(os.environ.get("INTERVAL", 600))
DAYS_LIMIT = int(os.environ.get("DAYS_LIMIT", 2))
PARSER_MAX_TEXT_LENGTH = int(os.environ.get("PARSER_MAX_TEXT_LENGTH", "8000"))
MODEL_TIMEOUT = int(os.getenv("MODEL_TIMEOUT", "60"))

# Timezone
try:
    APP_TZ = ZoneInfo(os.getenv("TIMEZONE", "UTC"))
except:
    APP_TZ = timezone.utc

# SSL (–∏–Ω–æ–≥–¥–∞ –≤ Termux –ø—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞–º–∏)
SSL_VERIFY = os.getenv("SSL_VERIFY", "1") == "1"
ssl_ctx = ssl.create_default_context()
if not SSL_VERIFY:
    ssl_ctx.check_hostname = False
    ssl_ctx.verify_mode = ssl.CERT_NONE

# ---- –ú–ï–ù–ï–î–ñ–ï–† –°–û–°–¢–û–Ø–ù–ò–Ø (DB) ----
class Database:
    def __init__(self, path):
        self.path = path
        self.conn = None

    async def connect(self):
        self.conn = await aiosqlite.connect(self.path)
        await self.conn.execute("PRAGMA journal_mode=WAL;")
        await self.conn.execute("""
            CREATE TABLE IF NOT EXISTS history (
                url TEXT NOT NULL,
                kind TEXT NOT NULL,
                timestamp INTEGER,
                PRIMARY KEY (url, kind)
            )
        """)
        await self.conn.commit()

    async def close(self):
        if self.conn:
            await self.conn.close()

    async def exists(self, kind: str, url: str) -> bool:
        if not self.conn: return False
        async with self.conn.execute("SELECT 1 FROM history WHERE url=? AND kind=?", (url, kind)) as cur:
            return await cur.fetchone() is not None

    async def add(self, kind: str, url: str):
        if not self.conn: return
        await self.conn.execute(
            "INSERT OR REPLACE INTO history (url, kind, timestamp) VALUES (?, ?, ?)", 
            (url, kind, int(time.time()))
        )
        await self.conn.commit()

    async def cleanup(self, days: int):
        cutoff = int(time.time() - (days * 86400))
        await self.conn.execute("DELETE FROM history WHERE timestamp < ?", (cutoff,))
        await self.conn.commit()

# ---- –ú–ï–ù–ï–î–ñ–ï–† META (JSON) ----
class MetaManager:
    def __init__(self, path):
        self.path = path
        self.data = {}
        self.load()

    def load(self):
        if os.path.exists(self.path):
            try:
                with open(self.path, "r", encoding="utf-8") as f: 
                    self.data = json.load(f)
            except: self.data = {}

    def save(self):
        try:
            with open(self.path, "w", encoding="utf-8") as f:
                json.dump(self.data, f)
        except: pass

    def get(self, key, default=None):
        return self.data.get(key, default)

    def set(self, key, value):
        self.data[key] = value
        self.save()

# ---- –ì–õ–û–ë–ê–õ–¨–ù–´–ï –û–ë–™–ï–ö–¢–´ ----
db = Database(DB_PATH)
meta_mgr = MetaManager(META_FILE)
_session = None

async def get_session():
    global _session
    if _session is None or _session.closed:
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –º–æ–±–∏–ª—å–Ω–æ–π —Å–µ—Ç–∏: –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–∞–π–º–∞—É—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è, –¥–ª–∏–Ω–Ω—ã–π —á—Ç–µ–Ω–∏—è
        timeout = aiohttp.ClientTimeout(total=45, connect=10)
        # keepalive_timeout –º–µ–Ω—å—à–µ, —á—Ç–æ–±—ã –Ω–µ –¥–µ—Ä–∂–∞—Ç—å –º–µ—Ä—Ç–≤—ã–µ —Å–æ–∫–µ—Ç—ã
        connector = aiohttp.TCPConnector(limit=50, ssl=ssl_ctx, ttl_dns_cache=300, keepalive_timeout=30)
        _session = aiohttp.ClientSession(connector=connector, timeout=timeout)
    return _session

bot = Bot(token=TELEGRAM_TOKEN, request=Request(connect_timeout=15, read_timeout=30))

# ---- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ----
def clean_text(text: str) -> str:
    if not text: return ""
    text = re.sub(r'\s+', ' ', text).strip()
    return text

async def fetch_url(url):
    session = await get_session()
    try:
        async with _network_semaphore:
            async with session.get(url, headers={"User-Agent": "TermuxBot/1.0"}, ssl=ssl_ctx) as response:
                if response.status == 200:
                    return await response.text()
    except Exception as e:
        logging.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
    return None

async def extract_content(url):
    """–ü—Ä–æ—Å—Ç–∞—è —ç–∫—Å—Ç—Ä–∞–∫—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤ Termux"""
    html_text = await fetch_url(url)
    if not html_text: return ""
    
    soup = BeautifulSoup(html_text, "html.parser")
    # –£–¥–∞–ª—è–µ–º –º—É—Å–æ—Ä
    for tag in soup(["script", "style", "nav", "footer", "iframe", "header"]):
        tag.decompose()
        
    # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
    text = ""
    article = soup.find('article')
    if article:
        text = article.get_text(" ", strip=True)
    else:
        # Fallback: –∏—â–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        paragraphs = soup.find_all('p')
        text = " ".join([p.get_text(" ", strip=True) for p in paragraphs])
        
    return text[:PARSER_MAX_TEXT_LENGTH]

# ---- AI SUMMARIZATION ----
async def summarize_gemini(text: str):
    if not GEMINI_KEYS: return None
    
    # –†–æ—Ç–∞—Ü–∏—è –∫–ª—é—á–µ–π
    idx = int(meta_mgr.get("gemini_idx", 0)) % len(GEMINI_KEYS)
    key = GEMINI_KEYS[idx]
    meta_mgr.set("gemini_idx", idx + 1)

    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={key}"
    payload = {
        "contents": [{"parts": [{"text": f"–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –±–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π):\n{text}"}]}]
    }
    
    session = await get_session()
    try:
        async with session.post(url, json=payload, timeout=MODEL_TIMEOUT) as resp:
            if resp.status != 200:
                logging.error(f"Gemini API Error: {resp.status}")
                return None
            data = await resp.json()
            return data["candidates"][0]["content"]["parts"][0]["text"]
    except Exception as e:
        logging.error(f"Gemini Exception: {e}")
        return None

async def summarize_ollama(text: str):
    # –õ–æ–∫–∞–ª—å–Ω—ã–π Ollama –Ω–∞ Termux
    url = "http://127.0.0.1:11434/api/generate"
    payload = {
        "model": OLLAMA_MODEL,
        "prompt": f"–†–µ–∑—é–º–∏—Ä—É–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:\n{text}",
        "stream": False,
        "options": {"num_ctx": 2048}
    }
    session = await get_session()
    try:
        async with session.post(url, json=payload, timeout=120) as resp:
            if resp.status == 200:
                data = await resp.json()
                return data.get("response", "")
    except Exception:
        pass
    return None

# ---- –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ ----
async def process_feed():
    logging.info("üì° –ü—Ä–æ–≤–µ—Ä–∫–∞ RSS –ª–µ–Ω—Ç...")
    session = await get_session()
    
    feeds_data = []
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ RSS
    tasks = [fetch_url(url) for url in RSS_URLS]
    results = await asyncio.gather(*tasks)
    
    for i, xml in enumerate(results):
        if not xml: continue
        try:
            feed = feedparser.parse(xml)
            source_title = feed.feed.get("title", RSS_URLS[i])
            for entry in feed.entries:
                # –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                pub_ts = time.time()
                if hasattr(entry, "published_parsed") and entry.published_parsed:
                    pub_ts = calendar.timegm(entry.published_parsed)
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç–∞—Ä–æ–µ
                if time.time() - pub_ts > DAYS_LIMIT * 86400: continue
                
                feeds_data.append({
                    "title": entry.get("title", "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"),
                    "link": entry.get("link", ""),
                    "source": source_title,
                    "ts": pub_ts
                })
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {RSS_URLS[i]}: {e}")

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: —Å—Ç–∞—Ä—ã–µ —Å–Ω–∞—á–∞–ª–∞, —á—Ç–æ–±—ã —Å–æ–±–ª—é—Å—Ç–∏ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—é –æ—Ç–ø—Ä–∞–≤–∫–∏, –∏–ª–∏ –Ω–æ–≤—ã–µ
    feeds_data.sort(key=lambda x: x["ts"])
    
    count = 0
    for item in feeds_data:
        if count >= NEWS_LIMIT: break
        link = item["link"]
        
        if await db.exists("sent", link) or await db.exists("seen", link):
            continue

        logging.info(f"üÜï –ù–æ–≤–∞—è —Å—Ç–∞—Ç—å—è: {item['title']}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content = await extract_content(link)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ —Å–ª–æ–≤
        combined_text = (item["title"] + " " + content).lower()
        if any(w in combined_text for w in BLOCKED_WORDS):
            logging.info(f"üö´ –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ (—Ñ–∏–ª—å—Ç—Ä): {item['title']}")
            await db.add("seen", link)
            continue
            
        if len(content.split()) < 20:
             logging.info("‚è≠Ô∏è –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è —Å—Ç–∞—Ç—å—è, –ø—Ä–æ–ø—É—Å–∫")
             await db.add("seen", link)
             continue

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∞–º–º–∞—Ä–∏
        summary = None
        if GEMINI_KEYS:
            summary = await summarize_gemini(content)
        
        # Fallback to Ollama if configured
        if not summary and OLLAMA_MODEL:
            logging.info("Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–±—É—é Ollama...")
            summary = await summarize_ollama(content)
            
        if not summary:
            summary = "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ."

        # –û—Ç–ø—Ä–∞–≤–∫–∞
        msg = (
            f"<b>{html.escape(item['title'])}</b>\n"
            f"üì° <i>{html.escape(item['source'])}</i>\n"
            f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            f"{html.escape(summary)}\n"
            f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            f"üîó <a href=\"{link}\">–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é</a>"
        )
        
        try:
            await bot.send_message(chat_id=CHAT_ID, text=msg, parse_mode="HTML")
            await db.add("sent", link)
            await db.add("seen", link)
            count += 1
            logging.info("‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
            await asyncio.sleep(3) # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
            await asyncio.sleep(5)

    # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ —Ü–∏–∫–ª–∞
    gc.collect()

async def main():
    await db.connect()
    # –ß–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑ –≤ —Å—É—Ç–∫–∏
    await db.cleanup(7)
    
    logging.info("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –≤ Termux")
    
    try:
        while True:
            try:
                await process_feed()
            except Exception as e:
                logging.error(f"–°–±–æ–π —Ü–∏–∫–ª–∞: {e}")
            
            logging.info(f"üí§ –°–æ–Ω {INTERVAL} —Å–µ–∫...")
            await asyncio.sleep(INTERVAL)
    except KeyboardInterrupt:
        logging.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞...")
    finally:
        await db.close()
        if _session:
            await _session.close()

if __name__ == "__main__":
    asyncio.run(main())